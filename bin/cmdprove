#!/bin/bash
#
# A test framework for Bash scripts.
#
# To see the full documentation, run this script passing
# the `--help` flag.
#
set -Eeu
set -o pipefail
trap 'echo "ERROR: An unrecoverable error occurred. Aborted." >&2; exit 3' EXIT
shopt -s extglob
#set -x

# Function: usage
#
#   Echoes usage string to stdout.
#
function usage {
  local name="$(basename "$0")"
cat <<EOF
EOF
}

# Config
set -u

#
# Globals

# The list of test files to execute:
test_file_list=()

# The list of existing functions in the environment whose name matches the pattern for a
# test function (used to exclude these from the test execution):
declare -A existing_func_named_test

# Set defaults for external variables not given:
#
: "${TEST_DEBUG:=}"
: "${TEST_OUT_DIR:=}"
# Functions whose name matches this pattern are considered tests:
: "${TEST_FUNC_PATTERN:=test_*}"


# Executes each test passed as argument in the command line
function run_all {
  parse_cmdline "$@"

  if [ "${#test_file_list[@]}" = 0 ]; then
    abort "No tests given. Pass '--help' to see usage."
  fi

  case "${TEST_OUT_DIR:-}" in '')
    TEST_OUT_DIR=`create_temp_dir /tmp/command-verify.XXXX` || exit 1
  esac
  debug "Output dir: $TEST_OUT_DIR"

  # Close stdin for the current process to avoid hangs, since test should not
  # rely on it. Tests must be self-contained and provide input to stdin, if
  # needed, to the processes they are testing.
  exec 0<&-

  # Execute each test script, counting the number of failed tests
  local failures=0
  local script
  for script in "${test_file_list[@]}"; do
    if ! run_test "$script"; then
      failures=$((failures + 1))
    fi
  done

  # Set return code:
  if [ "$failures" == 0 ]; then
    terminate 0
  else
    terminate 1
  fi
}

# Function: get_matching_functions {source_file} {func_name_pattern} {array_name}
#
#   Writes, to the array named `{array_name}`, the names of the shell functions existing
#   in the environment whose name matche the shell pattern `{func_name_pattern}` and
#   whose source file is `{source_file}`. Existing values in the output array are
#   discarded.
#
function get_matching_functions {
  local source_file="$1"
  local func_name_patn="$2"
  local -n matching_func_list="$3"

  # Save state for the `extdebug` shell option and set it to get extended function info.
  shopt -q extdebug
  local orig_extdebug=$?
  shopt -q -s extdebug

  # Get the list of all declared functions whose name matches the given pattern.
  local -a func_list
  local -a func_entry
  while read -r -a func_entry; do
    local func_name="${func_entry[2]:-}"
    case "$func_name" in $func_name_patn)
      func_list+=( "$func_name" ) 
    esac
  done < <(declare -F)

  # Mapping: function name => source line number
  local -A func_line

  # Get source file and line number for each of the functions
  local func_name
  for func_name in "${func_list[@]}"
  do
    local func_info="$(declare -F "$func_name")"

    # `func_info` is of the form: 'myfunction 123 ./my file.sh'
    # Will process it carefully to allow for spaces and other special characters in
    # file names.

    local -a info_words
    info_words=( $func_info )

    local err_pre="Internal: Invalid function declaration for '$func_name': '$func_info'"

    [ "${#info_words[@]}" -lt 3 ] && \
      test_error "$err_pre. Expected at least three fields, found ${#info_words[@]}."

    [[ "${info_words[0]}" != "$func_name" ]] && \
      test_error "$err_pre. First filed should match the function name."

    [[ "${info_words[1]}" != +([0-9]) ]] && \
      test_error "$err_pre. Second filed should be a positive decimal integer."
    
    local line_num="${info_words[1]}"

    # The file name is everything after the function name and line number:
    local file_start_char=$(( ${#func_name} + ${#line_num} + 2 ))
    local file_name="${func_info:$file_start_char}"

    # Discard functions not in the wanted file
    [ "$file_name" == "$source_file" ] || continue

    func_line[$func_name]="$line_num"
  done

  # Restore `extdebug` option
  if [ "$orig_extdebug" = 1 ]; then
    shopt -q -u extdebug
  fi

  sort_dict_keys_by_val 'func_line' 'matching_func_list'
}


# Function: sort_dict_keys_by_val {dict} {sorted_keys}
#
#   Sorts, in ascending order, the keys of dictionary named `{dict}` by their
#   corresponding values.  The sorted keys are stored in the array named `{sorted_keys}`.
#   Existing values in this array are removed.
#
function sort_dict_keys_by_val {
  local -n dict="$1"
  local -n keys="$2"

  keys=( "${!dict[@]}" )

  # Bubble sort
  local n=${#keys[@]}
  for ((i = 0; i < n-1; i++)); do
    for ((j = 0; j < n-i-1; j++)); do
      if [[ "${dict[${keys[j]}]}" -gt "${dict[${keys[j+1]}]}" ]]; then
        # Swap the elements
        local temp="${keys[j]}"
        keys[j]="${keys[j+1]}"
        keys[j+1]="$temp"
      fi
    done
  done
}


# Function: get_matching_functions {fname_pattern} {dict_name}
#
#   Add, as keys in the dictionary named `{dict_name}`, the names of the functions
#   existing in the environment whose name matches the pattern `{fname_pattern}`.
#
#   Values for the added keys are set to 1.
#
function _old_get_matching_functions {
  local pattern="$1"
  local -n dict="$2"

  local -a func_entry
  while read -r -a func_entry; do
    local func_name="${func_entry[2]:-}"
    case "$func_name" in $pattern)
      dict[$func_name]=1
    esac
  done < <(declare -F)
}


# Parses the command line, setting globals.
#
function parse_cmdline {
  local arg
  for arg in "$@"; do
    case "$arg" in
      --help)
        usage ; exit 0
      ;;
      --debug)
        TEST_DEBUG=1
      ;;
      -*)
        abort "Unknown option: '$arg'"
      ;;
      *)
        test_file_list+=( "$arg" )
      ;;
    esac
  done
}


# Executes a single test file in a subshell.
#
function run_test {
  local script="$1"

  [ -f "$script" ] || test_error "Test file not found: '$script'."

  # Set explicit './' path prefix for relative script paths, so that
  # `source` finds the right script:
  if [ "${script:0:1}" != '/' ]; then
    script="./$script"
  fi
  
  note "[RUNNING: $script]"

  # On a separate shell process, source the test script and then execute
  # our custom entry point:
  "$SHELL" -c "_before_test_script; source '$script'; _after_test_script '$script'"
  local rc=$?

  # Check exit status
  case "$rc" in
    0) echo "All tests passed in: '$script'" ;;
    1) echo "Some tests failed in: '$script'" ;;
    3) echo "Test script did not finish (or missing invocation to 'done_testing')" ;;
    *) echo "Unknown error when executing test script (retcode: $rc)." ;;
  esac

  return "$rc"
}

function _before_test_script {
  set -u
}

function _after_test_script {
  local script_path="$1"
  local -a test_functions
  get_matching_functions "$script_path" "$TEST_FUNC_PATTERN" 'test_functions'

  local test_function
  for test_function in "${test_functions[@]}"; do
    _test_control begin_subtest "$test_function"
    echo
    "$test_function"
    _test_control end_subtest
  done
}


# Function: describe (API)
#
#   Starts a test case.
#
function describe {
  note "$1"
}


function repeat_string {
  local string="$1"
  local count="$2"

  local idx=0
  local result=
  for (( idx=0 ; idx < count ; idx+=1 )); do
    result="${result}${string}"
  done

  printf '%s' "$result"
}


function prefix_lines {
  local prefix="$1"
  local text="$2"
  local line
  
  while IFS= read -r line || [ -n "$line" ]; do
    echo "${prefix}${line}"
  done <<< "$text"
}


# Writes a message if in debug mode
function debug {
  [ -n "$TEST_DEBUG" ] || return 0
  echo "# DBG: $*" >&2
}


function test_error() {
  echo "TEST ERROR: $@" >&2
  exit 3
}


function abort() {
  echo "ERROR: $@" >&2
  exit 2
}


# Function: assert (API)
#
#   Performs a basic assertion by comparing a command's output against expected values.
#   By default, empty strings are expected from `stdout` and `stderr`, other values can
#   be specified independently for each of them. A zero return code is also expected by
#   default, but a different value can be specified.
#
# Synopsys:
#
#   assert [-d] <description> [Options] -- <command>...
#
# Params:
#
#   <description> - A message to describe the assertion being tested (mandatory).
#   <command>...  - Command line to test (command and arguments). Must be preceeded by --.
#
# Options:
#
#   -d <description>
#     Since the description is mandatory, specifying `-d` before it is optional.
#     If `-d` is not given, then <description> must be the first argument.
#
#   (-o | -O) <expected_output>
#     Compare the <command>'s stdout against <expected_output>, which will be
#     interpreted as a literal string (-o) or as a file path to read (-O).
#
#   (-e | -E) <expected_error>
#     Like (-o, -O) but compare <command>'s stderr.
#     If not given, stderr will be expected to be the empty string ('').
#
#   (-r | -R) <expected_retcode>
#     Like (-o, -O) but compare <command>'s return code.
#     If not given, a 0 (zero) return code will be expected.
#
#   --
#     A literal argument '--' signals the end of option parsing.
#     This argument is mandatory, the rest of the arguments following it are the command
#     to test.
#     
# Environment:
#
#   TEST_NAME
#     User defined test name; defaults to 'test'. Since all logs are numbered,
#     you get test_01.out, test_02.out, ... if this var is not set.
#
#   TEST_OUT_DIR
#     Directory where output files will be written to.
#           
# Output:
#   
#   A message representing the result of the test.
#
function assert {
  local test_name='test'      # Set from env var TEST_NAME
  local description=
  local -a test_command
  #
  declare -A expected_arg
  declare -A expected_type
  declare -A expected_cmp
  declare -A expected_value
  declare -A expected_passed
  declare -A expected_arg_type

  expected_arg=(
    [out]=
    [err]=
    [ret]=
  )
  expected_passed=(
    [out]=
    [err]=
    [ret]=
  )
  expected_type=(
    [out]='string'
    [err]='string'
    [ret]='string'
  )
  expected_value=(
    [out]=''
    [err]=''
    [ret]=0
  )
  expected_cmp=(
    [out]='diff'
    [err]='diff'
    [ret]='diff'
  )

  #
  # Argument parsing
  debug "Assert: $@"

  # Check arguments
  if [ "${#@}" -lt 2 ]; then
    test_error "At least two arguments must be provided (description, command)."
    return;
  fi

  local opt_key=''
  local arg_count=0
  local value_needed=0

  for arg in "$@"; do

    arg_count=$(( arg_count + 1 ))

    if [ "$arg_count" = 1 ]; then
      case "$arg" in
        -*)
          # An option was passed as first argument; do nothing here,
          # will be processed next
          ;;
        *)
          # Not an option, interpret as description
          description="$arg"
          continue
      esac
    fi

    local exp_type=
    local exp_cmp=
    local key_expect=

    if [ "$value_needed" = 0 ]; then

      case "$arg" in
        --)
          # Explicit start of command (should be the first case)
          shift "$arg_count"
          test_command=( "$@" )
          break
          ;;
        -*)
          opt_key="$arg"
          value_needed=1  # All options require a value.
          ;;
        *)
          test_error \
            "Invalid command-line argument given to the assert function: '$arg'," \
            "(arg index: $arg_count)" \
            "Command-line was: $@"
          exit 3;
          ;;
      esac

    else
      value_needed=0

      case "$opt_key" in
        -d ) description="$arg" ;;
          
        -o | -e | -r ) exp_type='string'  ; exp_cmp='diff' ;;&
        -O | -E | -R ) exp_type='file'    ; exp_cmp='diff' ;;&
        -op | -ep )    exp_type='string'  ; exp_cmp='pattern' ;;&

        -o | -op | -O) key_expect=out ;;
        -e | -ep | -E) key_expect=err ;;
        -r | -R) key_expect=ret ;;

        *)
          test_error "Invalid option for 'assert()': '$opt_key'"
      esac

      expected_passed[$key_expect]=1
      expected_type[$key_expect]="$exp_type"
      expected_arg[$key_expect]="$arg"
      expected_cmp[$key_expect]="$exp_cmp"
    fi

  done


  if [ "${#test_command[@]}" == 0 ]; then
    test_error "Please specify a command to test."
    return;
  fi

  debug "Command to test: ${test_command[@]}"
  
  # Argument validation:

  if [ "$value_needed" = 1 ]; then
    test_error "Missing value for option: '$opt_key'"
    return
  fi

  if [ -z "$description" ]; then
    test_error "Please specify a description for the test case."
    return;
  fi

  _test_control begin_subtest "$description"

  # Populate expected values for direct comparison:
  #
  for key_expect in out err ret; do

    if [ -z "${expected_passed[$key_expect]}" ]; then
      # Not passed by the user, keep default
      continue
    fi

    exp_type="${expected_type[$key_expect]}"
    exp_arg="${expected_arg[$key_expect]}"

    case "$exp_type" in
      string|pattern)
        expected_value[$key_expect]="$exp_arg"
        ;;
      file)
        expected_value[$key_expect]="`cat "$exp_arg"`"
        if [ $? != 0 ]; then
          test_error "Failed to read master file (type $key_expect) '$exp_arg': $!"
          return
        fi
        ;;
      *)
        test_error "Invalid expected value type: '$exp_type'"
        return
    esac
  done

  if [ "${TEST_NAME+set}" = 'set' ]; then
    test_name="$TEST_NAME"
  else
    test_name='test'
  fi
  debug "test_name set to: '$test_name'."

  # Determine paths for output files
  out_base="$TEST_OUT_DIR/$test_name"

  declare -A outfile
  outfile=(
    [out]="`get_unique_file "$out_base" .out`"
    [err]="`get_unique_file "$out_base" .err`"
    [ret]="`get_unique_file "$out_base" .ret`"
  )

  debug "STDOUT will be saved to: '${outfile[out]}'."
  debug "STDERR will be saved to: '${outfile[err]}'."
  debug "RETCODE will be saved to: '${outfile[ret]}'."

  # Execute the command to test in a subshell to avoid interferring with the
  # testing framework. If stdin is provided to the invocation of this `assert`
  # function, it can be consumed by $command, automatically.
  # TODO: include timeout
  # TODO: verify if speciall characters in $command do not cause problems
  debug "Running test command ..."
  ( "${test_command[@]}" > "${outfile[out]}" 2>"${outfile[err]}" )

  # Save exit code
  local ret_code="$?"
  echo "$?" > "${outfile[ret]}"

  if [ "$ret_code" == "${expected_value[ret]}" ]; then
    _test_control set_pass 'Return code'
  else
    _test_control set_fail 'Return code'
    note "Got return code '$ret_code', expected '${expected_value[ret]}'."
  fi

  for check in out err; do
    local exp_str=${expected_value[$check]}
    local dif=$(_compare_files "${expected_cmp[$check]}"  <(echo -n "$exp_str") "${outfile[$check]}")

    if [ -z "$dif" ]; then
      _test_control set_pass "std$check"
    else
      _test_control set_fail "std$check"
      note ''
      note "Unexpected std$check:"
      note -l 1 "----------"
      note -l 1 "$dif"
      note -l 1 "----------"
      note -l 1 "[See: '${outfile[$check]}']"
      note ''
    fi
  done

  _test_control end_subtest
}


function _test_control {
  # Define globals if not present:
  : ${_pass_count:=0}
  : ${_fail_count:=0}
  : ${_test_idx:=0}
  : ${_test_level:=0}
  declare -g -a _nested_test_counts
  declare -g -a _nested_test_names

  local command="${1:-}"; shift
  local desc="${1:-}"

  case "$command" in
    begin_subtest)
      # Print subtest banner
      desc_label="${desc:+": $desc"}"
      note "Subtest${desc_label}"

      # Push current count
      _nested_test_counts+=( "$_test_idx" )
      _nested_test_names+=( "$desc" )
      _test_level=$((_test_level + 1))
      # Restart count
      _test_idx=0
    ;;
    end_subtest)
      if [ "$_test_level" == 0 ]; then
        test_error "Subtest stack underflow"
      fi
      # Pop the last count
      _test_idx="${_nested_test_counts[-1]}"
      local _subtest_name="${_nested_test_names[-1]}"
      unset _nested_test_counts[-1]
      unset _nested_test_names[-1]
      _test_level=$((_test_level - 1))

      local rc=0
      if [ "$_fail_count" -gt 0 ]; then
        _test_control set_fail "$_subtest_name"
        rc=1
      else
        _test_control set_pass "$_subtest_name"
      fi
      _test_control print_indent ""
      return $rc
    ;;
    set_pass)
      local desc_label="${desc:+ - $desc}"
      _test_idx=$((_test_idx + 1))
      _pass_count=$((_pass_count + 1))
      _test_control print_indent "ok ${_test_idx}${desc_label}"
    ;;
    set_fail)
      local desc_label="${desc:+ - $desc}"
      _test_idx=$((_test_idx + 1))
      _fail_count=$((_fail_count + 1))
      _test_control print_indent "not ok ${_test_idx}${desc_label}"
    ;;
    print_indent)
      local prefix="$(repeat_string '  ' "$_test_level")"
      prefix_lines "$prefix" "$*"
    ;;
    *)
      test_error "_test_control: Unknown subcommand: '$command'"
    ;;
  esac
}


# Function: note [-l {indent_level}] {multi_line}
#
#		Writes the {multi_line} string as a comment in the test output.
#		An indentation level {indent_level} can be specified, default is 0.
#   (This indentation is in addition to the current subtest indentation.)
#
function note {
	local indent_level=0
  if [ $# > 1 ] && [ "$1" == '-l' ]; then
    indent_level="$2"; shift 2
  fi
  local prefix="# $(repeat_string '  ' $indent_level)"
  local note_prefixed="$(prefix_lines "$prefix" "$*")"
	_test_control print_indent "$note_prefixed"
}


# Function: _compare_files {cmp_op} {file1} {file2}
#
#   Compares the contents of files {file1} and {file2} according to the comparison
#   operator {cmp_op}, which can take any of the following values:
#     'diff' - Perform and exact "diff" of the two files
#
function _compare_files {
  local cmp="$1"
  local exp="$2"
  local out="$3"

  case "$cmp" in
    diff)
      diff "$exp" "$out" 2>&1
    ;;
    pattern)
      local patn="$(cat "$exp")"
      local outs="$(cat "$out")"

      case "$outs" in
        *${patn}*)
          return 0
        ;;
        *)
          echo "Pattern not matched: '$patn'."
          echo "Output was: '$outs'."
        ;;
      esac
    ;;
    *)
      test_error "Unknown comparison operator: '$cmp'."
    ;;
  esac
}


# Function: create_temp_dir
#
#   Creates a temporary directory, trying with different methods.
#
function create_temp_dir()
{
  ( # Execute all commands in a subshell with stderr closed to reduce noise )
    exec 2>&- 

    template="$1"
    mktemp=
    dir=

    if mktemp=`command -v mktemp`; then
      if [ -n "$template" ] && dir=`$mktemp -d "$template"`; then
        echo "$dir"
      elif dir=`$mktemp -d`; then
        echo "$dir"
      fi
    elif dir="/tmp/$template/`date +%s`" && [ !-d "$dir" ] && mkdir "$dir"; then
      echo "$dir"
    else
      exit 1 
    fi
  ) || (
    echo "ERROR: Failed to create temp dir" >&2
    exit 1
  )
}


function get_unique_file {
  local name="$1"
  local ext="$2"
  local max_files=100

  for ((i=0; i<$max_files; i++)); do
    local candidate=`printf '%s%02d%s' "$name" $i "$ext"`
    if [ ! -e "$candidate" ]; then
      echo "$candidate" 
      return
    fi
  done

  test_error "TEST_ERROR: Could not determine a unique file name after $max_files attempts."
}


# Finish program execution gracefully
#
function terminate {
  # Use previous' command return code, unless $1 was given
  local rc=$?
  [ -n "${1:-}" ] && rc="$1"

  trap : EXIT # Clean error msg just before exiting
  exit "$rc"
}


# Export all the variables and functions we want test files to have available.
export TEST_DEBUG
export TEST_OUT_DIR
export TEST_FUNC_PATTERN
#
export -f describe
export -f assert
export -f note
export -f debug
export -f test_error
#
export -f prefix_lines
export -f repeat_string
export -f sort_dict_keys_by_val
export -f get_unique_file
export -f get_matching_functions
#
export -f _compare_files
export -f _test_control
export -f _before_test_script
export -f _after_test_script

# Entry point
run_all "$@"

